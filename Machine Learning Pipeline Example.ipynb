{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction to Machine Learning Pipeline Workshop\n",
    "=============\n",
    "\n",
    "We can start the iPython notebook by running the ./start.sh script or \n",
    "\n",
    "PYSPARK_DRIVER_PYTHON=\"ipython\" PYSPARK_DRIVER_PYTHON_OPTS=\"notebook\" ${SPARK_HOME}/bin/pyspark --packages com.databricks:spark-csv_2.10:1.3.0\n",
    "\n",
    "or pre-2.0\n",
    "\n",
    "IPYTHON_OPTS=\"notebook\" ${SPARK_HOME}/spark/bin/pyspark --packages com.databricks:spark-csv_2.10:1.3.0\n",
    "\n",
    "From here we can see that we already have a SparkContext & SQLContext ready to go:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x7fcf931f7310>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.context.SQLContext at 0x7fcf90ccb350>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we start by downloading loading some data which is in csv format so its a good thing we got that csv package included already for us.\n",
    "\n",
    "Note: the data is a modified version of https://archive.ics.uci.edu/ml/datasets/Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = sqlContext.read.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").load(\"resources/adult.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: string, workclass: string, fnlwgt: string, education: string, education-num: string, maritial-status: string, occupation: string, relationship: string, race: string, sex: string, capital-gain: string, capital-loss: string, hours-per-week: string, native-country: string, category: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(age=u'39', workclass=u' State-gov', fnlwgt=u' 77516', education=u' Bachelors', education-num=u' 13', maritial-status=u' Never-married', occupation=u' Adm-clerical', relationship=u' Not-in-family', race=u' White', sex=u' Male', capital-gain=u' 2174', capital-loss=u' 0', hours-per-week=u' 40', native-country=u' United-States', category=u' <=50K')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as we can see Spark has simply loaded all of the values as strings since we haven't specified another schema. We can isntead ask it to infer the schema and also handle this extra space magic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = sqlContext.read.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"resources/adult.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(age=39, workclass=u' State-gov', fnlwgt=77516.0, education=u' Bachelors', education-num=13.0, maritial-status=u' Never-married', occupation=u' Adm-clerical', relationship=u' Not-in-family', race=u' White', sex=u' Male', capital-gain=2174.0, capital-loss=0.0, hours-per-week=40.0, native-country=u' United-States', category=u' <=50K')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: int, workclass: string, fnlwgt: double, education: string, education-num: double, maritial-status: string, occupation: string, relationship: string, race: string, sex: string, capital-gain: double, capital-loss: double, hours-per-week: double, native-country: string, category: string]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we import a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.param import Param, Params\n",
    "from pyspark.ml.feature import Bucketizer, VectorAssembler, StringIndexer\n",
    "from pyspark.ml import Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is prepairing the features, here we are just choosing existing numeric features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=[\"age\", \"education-num\"], outputCol=\"feautres\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the vector assembler only works on doubles, so we need to take our category and turn it into a double. The StringIndexer will do this for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol=\"category\").setOutputCol(\"category-index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline().setStages([assembler, indexer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then need to \"fit\" our pipeline. This allows the StringIndexer to determine what strings will be assigned what indexes in the eventual transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model=pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then transform our data into the prepaired format for our machine learning model to work on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prepared = model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(age=39, workclass=u' State-gov', fnlwgt=77516.0, education=u' Bachelors', education-num=13.0, maritial-status=u' Never-married', occupation=u' Adm-clerical', relationship=u' Not-in-family', race=u' White', sex=u' Male', capital-gain=2174.0, capital-loss=0.0, hours-per-week=40.0, native-country=u' United-States', category=u' <=50K', feautres=DenseVector([39.0, 13.0]), category-index=0.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(labelCol = \"category-index\", featuresCol=\"feautres\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we fit on the prepared data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt_model = dt.fit(prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_4caaa33595b6d98d0500) of depth 5 with 61 nodes"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we could make this part of the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline_and_model = Pipeline().setStages([assembler, indexer, dt])\n",
    "pipeline_model = pipeline_and_model.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(prediction=1.0, category-index=0.0),\n",
       " Row(prediction=1.0, category-index=0.0),\n",
       " Row(prediction=0.0, category-index=0.0),\n",
       " Row(prediction=0.0, category-index=0.0),\n",
       " Row(prediction=0.0, category-index=0.0),\n",
       " Row(prediction=1.0, category-index=0.0),\n",
       " Row(prediction=0.0, category-index=0.0),\n",
       " Row(prediction=0.0, category-index=1.0),\n",
       " Row(prediction=1.0, category-index=1.0),\n",
       " Row(prediction=1.0, category-index=1.0),\n",
       " Row(prediction=0.0, category-index=1.0),\n",
       " Row(prediction=0.0, category-index=1.0),\n",
       " Row(prediction=0.0, category-index=0.0),\n",
       " Row(prediction=0.0, category-index=0.0),\n",
       " Row(prediction=0.0, category-index=1.0),\n",
       " Row(prediction=0.0, category-index=0.0),\n",
       " Row(prediction=0.0, category-index=0.0),\n",
       " Row(prediction=0.0, category-index=0.0),\n",
       " Row(prediction=0.0, category-index=0.0),\n",
       " Row(prediction=1.0, category-index=1.0)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model.transform(prepared).select(\"prediction\", \"category-index\").take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(prediction=1.0, category-index=0.0),\n",
       " Row(prediction=1.0, category-index=0.0),\n",
       " Row(prediction=0.0, category-index=0.0),\n",
       " Row(prediction=0.0, category-index=0.0),\n",
       " Row(prediction=0.0, category-index=0.0),\n",
       " Row(prediction=1.0, category-index=0.0),\n",
       " Row(prediction=0.0, category-index=0.0),\n",
       " Row(prediction=0.0, category-index=1.0),\n",
       " Row(prediction=1.0, category-index=1.0),\n",
       " Row(prediction=1.0, category-index=1.0),\n",
       " Row(prediction=0.0, category-index=1.0),\n",
       " Row(prediction=0.0, category-index=1.0),\n",
       " Row(prediction=0.0, category-index=0.0),\n",
       " Row(prediction=0.0, category-index=0.0),\n",
       " Row(prediction=0.0, category-index=1.0),\n",
       " Row(prediction=0.0, category-index=0.0),\n",
       " Row(prediction=0.0, category-index=0.0),\n",
       " Row(prediction=0.0, category-index=0.0),\n",
       " Row(prediction=0.0, category-index=0.0),\n",
       " Row(prediction=1.0, category-index=1.0)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_model.transform(df).select(\"prediction\", \"category-index\").take(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about if we had these as the label names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = list(pipeline_model.stages[1].labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import IndexToString\n",
    "inverter = IndexToString(inputCol=\"prediction\", outputCol=\"prediction-label\", labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(prediction-label=u' >50K', category=u' <=50K'),\n",
       " Row(prediction-label=u' >50K', category=u' <=50K'),\n",
       " Row(prediction-label=u' <=50K', category=u' <=50K'),\n",
       " Row(prediction-label=u' <=50K', category=u' <=50K'),\n",
       " Row(prediction-label=u' <=50K', category=u' <=50K'),\n",
       " Row(prediction-label=u' >50K', category=u' <=50K'),\n",
       " Row(prediction-label=u' <=50K', category=u' <=50K'),\n",
       " Row(prediction-label=u' <=50K', category=u' >50K'),\n",
       " Row(prediction-label=u' >50K', category=u' >50K'),\n",
       " Row(prediction-label=u' >50K', category=u' >50K'),\n",
       " Row(prediction-label=u' <=50K', category=u' >50K'),\n",
       " Row(prediction-label=u' <=50K', category=u' >50K'),\n",
       " Row(prediction-label=u' <=50K', category=u' <=50K'),\n",
       " Row(prediction-label=u' <=50K', category=u' <=50K'),\n",
       " Row(prediction-label=u' <=50K', category=u' >50K'),\n",
       " Row(prediction-label=u' <=50K', category=u' <=50K'),\n",
       " Row(prediction-label=u' <=50K', category=u' <=50K'),\n",
       " Row(prediction-label=u' <=50K', category=u' <=50K'),\n",
       " Row(prediction-label=u' <=50K', category=u' <=50K'),\n",
       " Row(prediction-label=u' >50K', category=u' >50K')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverter.transform(pipeline_model.transform(df)).select(\"prediction-label\", \"category\").take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_4caaa33595b6d98d0500) of depth 5 with 61 nodes"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_model.stages[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: int, min(hours-per-week): double, avg(hours-per-week): double, max(capital-gain): double]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df.groupBy(\"age\").agg(min(\"hours-per-week\"), avg(\"hours-per-week\"), max(\"capital-gain\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "windowSpec = Window.partitionBy(\"age\").orderBy(\"capital-gain\").rowsBetween(-100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+----------------------------------------------------------------------------------------------------------------+\n",
      "|age|capital-gain|avg(capital-gain) OVER (PARTITION BY age ORDER BY capital-gain ASC ROWS BETWEEN 100 PRECEDING AND 100 FOLLOWING)|\n",
      "+---+------------+----------------------------------------------------------------------------------------------------------------+\n",
      "| 52|     99999.0|                                                                                              11563.377358490567|\n",
      "| 52|     99999.0|                                                                                              11900.174757281553|\n",
      "| 28|     99999.0|                                                                                               4736.762376237623|\n",
      "| 44|     99999.0|                                                                                                9865.47572815534|\n",
      "| 52|     99999.0|                                                                                               11349.24074074074|\n",
      "| 44|     99999.0|                                                                                              10060.831683168317|\n",
      "| 28|     99999.0|                                                                                               4690.323529411765|\n",
      "| 53|     99999.0|                                                                                               8220.173076923076|\n",
      "| 53|     99999.0|                                                                                               8299.980582524271|\n",
      "| 44|     99999.0|                                                                                               9770.615384615385|\n",
      "| 31|     99999.0|                                                                                               4793.683168316832|\n",
      "| 65|     99999.0|                                                                                                6149.21568627451|\n",
      "| 53|     99999.0|                                                                                               8464.336633663366|\n",
      "| 44|     99999.0|                                                                                               9962.196078431372|\n",
      "| 34|     99999.0|                                                                                               5285.564356435643|\n",
      "| 65|     99999.0|                                                                                              6210.0990099009905|\n",
      "| 53|     99999.0|                                                                                                8381.35294117647|\n",
      "| 65|     99999.0|                                                                                               6030.961538461538|\n",
      "| 78|     99999.0|                                                                                               5208.217391304348|\n",
      "| 65|     99999.0|                                                                                               6089.514563106796|\n",
      "+---+------------+----------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df[\"age\"], df['capital-gain'], avg(\"capital-gain\").over(windowSpec)).orderBy(desc(\"capital-gain\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
